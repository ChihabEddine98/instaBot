{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# â“µ Useful Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web ï¼ \n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Visualisation ðŸ“Š\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# Time ðŸ•¦\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_From_Posts(number_of_posts,outfile_name):\n",
    "    \n",
    "    with open(outfile_name+'_posts.json', 'r') as f:\n",
    "        arr = json.loads(f.read()) # load json data from previous step\n",
    "    \n",
    "    print(\"Opening of \"+outfile_name+\"_posts.json successful\")  \n",
    "    posts_data = []\n",
    "    coms= []\n",
    "    url_imgs= []\n",
    "    hashtags= []\n",
    "    number_of_posts_limit=number_of_posts\n",
    "    number_of_posts=0\n",
    "    successful_requests=0\n",
    "    failed_requests=0\n",
    "    kicked_requests=0\n",
    "    print(\"Start retrieving posts data\")\n",
    "    for item in arr:\n",
    "        if(number_of_posts<number_of_posts_limit):\n",
    "            shortcode = item['shortcode']\n",
    "            url = \"https://www.instagram.com/p/{0}/?__a=1\".format(shortcode)\n",
    "            while True:\n",
    "                try:\n",
    "                    r = requests.get(url,timeout = 5)\n",
    "                    time.sleep(500)\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "                break\n",
    "            if ( r.status_code==200):\n",
    "                number_of_posts+=1\n",
    "                successful_requests+=1\n",
    "                data = json.loads(r.text)\n",
    "                #print(data)\n",
    "                try:\n",
    "                    location = data['graphql']['shortcode_media']['location']['name'] # get location for a post\n",
    "\n",
    "                except:\n",
    "                     location = '' # if location is NULL\n",
    "\n",
    "\n",
    "                likes=data['graphql']['shortcode_media']['edge_media_preview_like']['count'] #ok\n",
    "\n",
    "                try :\n",
    "                    number_coms=data['graphql']['shortcode_media']['edge_media_to_parent_comment']['count'] #ok\n",
    "                except :\n",
    "                    number_coms=data['graphql']['shortcode_media']['edge_media_to_comment']['count']\n",
    "\n",
    "                coms=[]\n",
    "\n",
    "                try :\n",
    "                    for nodes in data['graphql']['shortcode_media']['edge_media_to_parent_comment']['edges']:\n",
    "                        coms.append(nodes['node']['text'])\n",
    "                except:\n",
    "                    try : \n",
    "                        for nodes in data['graphql']['shortcode_media']['edge_media_to_comment']['edges']:\n",
    "                            coms.append(nodes['node']['text'])\n",
    "\n",
    "                    except : \n",
    "                        coms.append(\"\")\n",
    "\n",
    "                url_img=data['graphql']['shortcode_media']['display_url'] # ok \n",
    "                if (len(data['graphql']['shortcode_media']['edge_media_to_caption']['edges'])>0):\n",
    "                    text=data['graphql']['shortcode_media']['edge_media_to_caption']['edges'][0]['node']['text'] #ok\n",
    "                else :\n",
    "                    text=\"\"\n",
    "                hashtags=Hashtags_From_Text(text)\n",
    "                posts_data.append({'Shortcode': shortcode,'Likes': likes,'Hashtags': hashtags,'Number of com\\'s' : number_coms ,'Com\\'s': coms ,'Text': text,'Url_img' : url_img,'Location': location})\n",
    "                r.status_code=404\n",
    "            else :\n",
    "                failed_requests+=1\n",
    "        time.sleep(10)\n",
    "                \n",
    "    #print(\"Requests successful : \",successful_requests)\n",
    "    #print(\"Requests failed : \",failed_requests)\n",
    "    print(\"Kicked requests : \",kicked_requests)\n",
    "    with open(outfile_name+'_posts_data.json', 'w') as outfile:\n",
    "        json.dump(posts_data, outfile) # save to json\n",
    "    print(outfile_name+'_posts_data.json has been created')\n",
    "    df=pd.read_json(outfile_name+\"_posts_data.json\")\n",
    "    df.to_csv(outfile_name+'_data_results.csv')\n",
    "    print(outfile_name+'_data_results.csv has been created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Posts_Data_From_Tag(tag,number_of_posts,outfile_name,minimum_likes,request_time_limit):\n",
    "    end_cursor = '' # empty for the 1st page\n",
    "    print(\"Start retrieving posts data from hashtag: \",tag,)\n",
    "    print(\"Number of posts requested: \",number_of_posts)\n",
    "    successful_requests=0\n",
    "    failed_requests=0\n",
    "    kicked_requests=0\n",
    "    kicked_limit=10\n",
    "    posts_data=[]\n",
    "    currentDT = datetime.datetime.now()\n",
    "    currentDT_month=str(currentDT.month)\n",
    "    currentDT_day=str(currentDT.day)\n",
    "    pages_retrieved = 0\n",
    "    posts_retrieved=0\n",
    "    if (len(currentDT_month)==1):\n",
    "        currentDT_month=\"0\"+currentDT_month\n",
    "    if (len(currentDT_day)==1):\n",
    "        currentDT_day=\"0\"+currentDT_day\n",
    "    \n",
    "    currentDT=currentDT_day+currentDT_month+str(currentDT.year)\n",
    "    request_time_limit+=2\n",
    "    time_limit=time.time()\n",
    "    while(posts_retrieved<number_of_posts):\n",
    "        if ( time.time() - time_limit > request_time_limit) : \n",
    "            print(\"Exceeded time request to retrieve more posts\")\n",
    "            break\n",
    "        url = \"https://www.instagram.com/explore/tags/{0}/?__a=1&max_id={1}\".format(tag, end_cursor)\n",
    "        kicked_times=0\n",
    "        while True and kicked_times<kicked_limit:\n",
    "            try:\n",
    "                r = requests.get(url,timeout = 2)\n",
    "            except Exception as e:\n",
    "                time.sleep(1)\n",
    "                kicked_requests+=1\n",
    "                kicked_times+=1\n",
    "                continue\n",
    "            break\n",
    "        if ( r.status_code == 200):\n",
    "            raw_data = r.text\n",
    "            data = json.loads(raw_data.strip(),strict = False)\n",
    "            #print(data)\n",
    "            \n",
    "            edge_hashtag= data['graphql']['hashtag']\n",
    "            edge_hashtag_to_media=edge_hashtag['edge_hashtag_to_media']\n",
    "            \n",
    "            end_cursor = edge_hashtag_to_media ['page_info']['end_cursor'] # value for the next page\n",
    "            \n",
    "            edges = edge_hashtag_to_media ['edges'] # list with posts\n",
    "            if(posts_retrieved==0):\n",
    "                tag_id = edge_hashtag['id']\n",
    "                tag_name = tag\n",
    "                number_of_post_with_hashtag = edge_hashtag_to_media['count']\n",
    "            page_time_start=time.time()\n",
    "            for node in edges:\n",
    "                if(posts_retrieved<number_of_posts):\n",
    "                    post=node['node']\n",
    "                    likes=post['edge_liked_by']['count']\n",
    "                    if(likes>=minimum_likes):\n",
    "                        #print(\"Retrieving post number\",retrieved_post_number, \"from page \",i)\n",
    "                        owner_id = post['owner']['id']\n",
    "                        timestamp = post['taken_at_timestamp']\n",
    "                        shortcode=post['shortcode']\n",
    "                        try :\n",
    "                            number_coms=post['edge_media_to_comment']['count'] \n",
    "                        except :\n",
    "                            number_coms=post['edge_media_parent_to_comment']['count']\n",
    "\n",
    "                        coms=[]\n",
    "\n",
    "                        url_img=post['display_url'] \n",
    "                        edges_media=post['edge_media_to_caption']['edges']\n",
    "                        if (len(edges_media)>0):\n",
    "                            text=edges_media[0]['node']['text'] \n",
    "                        else :\n",
    "                            text=\"\"\n",
    "\n",
    "                        hashtags=Hashtags_From_Text(text)\n",
    "                        mentions=Mentions_From_Text(text)\n",
    "                        if( post[\"is_video\"]==False):\n",
    "                            img_description=post[\"accessibility_caption\"]\n",
    "                            if(img_description.find(\":\") !=-1):\n",
    "                                img_description=img_description[img_description.index(\":\")+1:]\n",
    "                            else:\n",
    "                                img_description=\"Null\"\n",
    "                        else:\n",
    "                            img_description=\"Video\"\n",
    "                        posts_data.append({'Tag_Id': tag_id,'Tag_Name': tag_name,'Extraction_Date':currentDT,'Posts_W_Hashtag':number_of_post_with_hashtag,'Owner_Id': owner_id,'Shortcode': shortcode,'Timestamp': timestamp,'Likes': likes,'Hashtags': hashtags,'Mentions': mentions,'Com\\'s' : number_coms ,'Text': text,'Img_Description' : img_description,'Url_Img' : url_img})\n",
    "                        r.status_code=404\n",
    "                        posts_retrieved+=1\n",
    "                        if (posts_retrieved%10==0):\n",
    "                            print(posts_retrieved,\" Posts retrieved\")\n",
    "                        time_limit=time.time()\n",
    "            pages_retrieved+=1\n",
    "            page_time_end=time.time()\n",
    "            #print(\"Page number :\",pages_retrieved,\" retrieved - \",\"Time :\",page_time_end-page_time_start)\n",
    "        else :\n",
    "            failed_requests+=1\n",
    "                \n",
    "    #print(\"Requests successful : \",successful_requests)\n",
    "    #print(\"Requests failed : \",failed_requests)\n",
    "    print(\"Kicked requests : \",kicked_requests)\n",
    "    \n",
    "    with open(\"#\"+outfile_name+'_posts_data.json', 'w') as outfile:\n",
    "        json.dump(posts_data, outfile) # save to json\n",
    "    print(\"#\"+outfile_name+'_posts_data.json has been created')\n",
    " \n",
    "    #post = posts_data[0].keys()\n",
    "   # with open(\"#\"+outfile_name+'_posts_data.csv', 'w') as outfile:\n",
    "    #    dict_writer = csv.DictWriter(outfile, post)\n",
    "    #    dict_writer.writeheader()\n",
    "    #    dict_writer.writerows(posts_data)\n",
    "\n",
    "\n",
    "    print(\"Process finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.instagram.com/bakary.gassama8\"\n",
    "\n",
    "r = requests.get(url,timeout = 5)\n",
    "print(r.text)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
